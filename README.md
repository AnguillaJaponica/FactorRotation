# Rotated Word Vector Representations and their Interpretability


## Overview
We open a TensorFlow Python source file for Rotated Word Vector Representations and their Interpretability.

The paper is published in EMNLP 2017. [<a href="http://aclweb.org/anthology/D17-1041">paper</a>, <a href="https://sungjoonpark.github.io./assets/emnlp2017_poster.pdf">poster</a>]

These files are originated in a Python version of the gradient projection rotation
algorithms (GPA) developed by Bernaards, C.A. and Jennrich, R.I.

If you need more extended version of factor rotation algorithms, you can visit:
https://github.com/mvds314/factor_rotation


## Requirements
- Python 3
- TensorFlow 1.0
- NumPy
- gensim
- pandas


## How to Run
First, you should bring input word vector representation.

Input of the program is word vector representation.
Output of the program is rotated word vector representation.
The format of the file is same as input one.



### Run the program
To run the program, you just run the test python file.

```sh
python example.py
```


## Reference

Robert I Jennrich. 2001. A simple general procedurefor orthogonal rotation.Psychometrika66(2):289â€“306
